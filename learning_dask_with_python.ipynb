{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distributed-sound",
   "metadata": {},
   "source": [
    "# Data Science with Python and Dask\n",
    "\n",
    "**Author:** David-Alexandre Guenette <br />\n",
    "**Date:** 2021-01-20 <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-thong",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-light",
   "metadata": {},
   "source": [
    "**Problem:** What patterns can we find in the data that are correlated with increases or decreases in the number of parking tickets issued by the New York City parking authority?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-apartment",
   "metadata": {},
   "source": [
    "**Hypothesis:** \n",
    "\n",
    " - We might find that older vehicles are more likely to receibe tickets.\n",
    " - We might find that a particular color attracts more attention from the parking authority than other colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-fleece",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-verse",
   "metadata": {},
   "source": [
    "#### Importing CSV files using Dask defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "skilled-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "fy14 = dd.read_csv('./data/nyu_parking_data/parking_violations_2014.csv')\n",
    "fy15 = dd.read_csv('./data/nyu_parking_data/parking_violations_2015.csv')\n",
    "fy16 = dd.read_csv('./data/nyu_parking_data/parking_violations_2016.csv')\n",
    "fy17 = dd.read_csv('./data/nyu_parking_data/parking_violations_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-blank",
   "metadata": {},
   "source": [
    "#### Finding the common columns between the four DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "educated-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def set_columns(df):\n",
    "    \"\"\"\n",
    "    Purpose : Make a set of columns from DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    scolumns = set(df.columns)\n",
    "    return scolumns\n",
    "\n",
    "\n",
    "def find_common_columns(ls):\n",
    "    \"\"\"\n",
    "    Purpose : Takes a list of columns sets object to make a common list of columns name\n",
    "    \"\"\"\n",
    "    \n",
    "    cc = list(reduce(lambda a, i: a.intersection(i), ls))\n",
    "    return cc\n",
    "\n",
    "\n",
    "\n",
    "columns = [\n",
    "    set_columns(fy14),\n",
    "    set_columns(fy15),\n",
    "    set_columns(fy16),\n",
    "    set_columns(fy17)\n",
    "]\n",
    "\n",
    "common_columns = find_common_columns(columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-worst",
   "metadata": {},
   "source": [
    "#### Building a generic schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "comfortable-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# First we need to build a dictionary that maps column names to datatypes. \n",
    "dtypes = {\n",
    " 'Date First Observed': np.str,\n",
    " 'Days Parking In Effect    ': np.str,\n",
    " 'Double Parking Violation': np.str,\n",
    " 'Feet From Curb': np.float32,\n",
    " 'From Hours In Effect': np.str,\n",
    " 'House Number': np.str,\n",
    " 'Hydrant Violation': np.str,\n",
    " 'Intersecting Street': np.str,\n",
    " 'Issue Date': np.str,\n",
    " 'Issuer Code': np.float32,\n",
    " 'Issuer Command': np.str,\n",
    " 'Issuer Precinct': np.float32,\n",
    " 'Issuer Squad': np.str,\n",
    " 'Issuing Agency': np.str,\n",
    " 'Law Section': np.float32,\n",
    " 'Meter Number': np.str,\n",
    " 'No Standing or Stopping Violation': np.str,\n",
    " 'Plate ID': np.str,\n",
    " 'Plate Type': np.str,\n",
    " 'Registration State': np.str,\n",
    " 'Street Code1': np.uint32,\n",
    " 'Street Code2': np.uint32,\n",
    " 'Street Code3': np.uint32,\n",
    " 'Street Name': np.str,\n",
    " 'Sub Division': np.str,\n",
    " 'Summons Number': np.uint32,\n",
    " 'Time First Observed': np.str,\n",
    " 'To Hours In Effect': np.str,\n",
    " 'Unregistered Vehicle?': np.str,\n",
    " 'Vehicle Body Type': np.str,\n",
    " 'Vehicle Color': np.str,\n",
    " 'Vehicle Expiration Date': np.str,\n",
    " 'Vehicle Make': np.str,\n",
    " 'Vehicle Year': np.float32,\n",
    " 'Violation Code': np.uint16,\n",
    " 'Violation County': np.str,\n",
    " 'Violation Description': np.str,\n",
    " 'Violation In Front Of Or Opposite': np.str,\n",
    " 'Violation Legal Code': np.str,\n",
    " 'Violation Location': np.str,\n",
    " 'Violation Post Code': np.str,\n",
    " 'Violation Precinct': np.float32,\n",
    " 'Violation Time': np.str\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-circulation",
   "metadata": {},
   "source": [
    "#### Applying the schema to all four DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "miniature-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.read_csv('./data/nyu_parking_data/*.csv', dtype=dtypes, usecols=common_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-criticism",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
